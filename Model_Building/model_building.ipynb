{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e44ecc-688b-4380-97e7-b0d5be10ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/Subbu/OneDrive/Desktop/M.TechStuff/Sem2/2.DMML/Assignment/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d7400c-0093-4c97-83d2-5604affc67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b844a830-04fb-4a04-b6f5-d8e7c4e1faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/Subbu/OneDrive/Desktop/M.TechStuff/Sem2/2.DMML/Assignment/Model_Building/mlruns\")\n",
    "mlflow.set_experiment(\"Customer Churn Prediction\")\n",
    "\n",
    "# Enable notebook mode\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2261c4c-ed2d-486e-87f6-0294dddd18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 21:33:37 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/03/13 21:33:47 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/03/13 21:34:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model logged to MLflow\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8204\n",
      "Precision: 0.6933\n",
      "Recall: 0.5802\n",
      "F1-Score: 0.6317\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/13 21:34:18 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/03/13 21:34:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model logged to MLflow\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8013\n",
      "Precision: 0.6667\n",
      "Recall: 0.5027\n",
      "F1-Score: 0.5732\n",
      "\n",
      "Model performance results saved at 'C:/Users/Subbu/OneDrive/Desktop/M.TechStuff/Sem2/2.DMML/Assignment/Model_Building/model_performance.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from Data_Transformation.connection import SnowflakeConnection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def get_all_features():\n",
    "    \"\"\"Retrieve all features from the feature store.\"\"\"\n",
    "    conn = SnowflakeConnection()\n",
    "    query = \"\"\"\n",
    "    WITH LatestFeatures AS (\n",
    "        SELECT *, ROW_NUMBER() OVER (PARTITION BY \"customerID\" ORDER BY FEATURE_VERSION DESC) AS rn\n",
    "        FROM CUSTOMER_CHURN.PUBLIC.FEATURE_STORE_TABLE\n",
    "    )\n",
    "    SELECT * FROM LatestFeatures WHERE rn = 1;\n",
    "    \"\"\"\n",
    "    df = conn.execute_query(query)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "# Define directories\n",
    "OUTPUT_DIR = \"C:/Users/Subbu/OneDrive/Desktop/M.TechStuff/Sem2/2.DMML/Assignment/Model_Building/\"\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "df = get_all_features()\n",
    "\n",
    "# Remove non-numeric columns\n",
    "if \"customerID\" in df.columns:\n",
    "    df.drop(columns=[\"customerID\"], inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "if \"Churn\" not in df.columns:\n",
    "    raise KeyError(\"The target column 'Churn' is missing from the dataset.\")\n",
    "\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"Customer Churn Prediction\") \n",
    "\n",
    "# Train and evaluate models using MLflow\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, name)\n",
    "        print(f\"{name} Model logged to MLflow\")\n",
    "\n",
    "        results.append([name, accuracy, precision, recall, f1])\n",
    "\n",
    "        print(f\"{name} Performance:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\\n\")\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "results_path = os.path.join(OUTPUT_DIR, \"model_performance.csv\")\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"Model performance results saved at '{results_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d19a206-f6ea-4e8c-868a-e046790b5e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bbc4a1-33d6-43bb-84d9-44c934915ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b1c388-4ce0-4277-b0ac-2878262f3ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: C:/Users/Subbu/OneDrive/Desktop/M.TechStuff/Sem2/2.DMML/Assignment/Model_Building/best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Load the best model\n",
    "logged_model = \"C:/Users/Subbu/OneDrive/Desktop/M.TechStuff/Sem2/2.DMML/Assignment/Model_Building/mlruns/621738802032390636/87b7aebe71af4ad291e41fa55e58f8f9/artifacts/model\"\n",
    "model = mlflow.sklearn.load_model(logged_model)\n",
    "\n",
    "\n",
    "model_path = \"C:/Users/Subbu/OneDrive/Desktop/M.TechStuff/Sem2/2.DMML/Assignment/Model_Building/best_model.pkl\"\n",
    "\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f\"Best model saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c10cfbd-7b32-4cfe-8b61-39704e0d4129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded and predictions made.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "with open(model_path, \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "print(\"Model successfully loaded and predictions made.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
